{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKZr+WtQHCPUb1xt4C8g9k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h6eEAkcrKtSU"},"outputs":[],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.pipeline import Pipeline\n","import joblib\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import string\n","import os\n","\n","# Veri seti ve NLTK gereksinimlerini yükleme\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Modeli kaydetme ve yükleme için dosya yolları\n","model_filename = '../pythonProject/trained_model.pkl'\n","vectorizer_filename = '../pythonProject/tfidf_vectorizer.pkl'\n","\n","def preprocess_text(text):\n","    text = text.lower()  # Küçük harfe çevir\n","    text = text.translate(str.maketrans('', '', string.punctuation))  # Noktalama işaretlerini kaldır\n","    return text\n","\n","lemmatizer = WordNetLemmatizer()\n","def lemmatize_text(text):\n","    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n","\n","def train_and_save_model():\n","    print(\"Veri yükleniyor...\")\n","\n","    # Dataset'i yükleme\n","    file_path = 'ml_dataset.csv'\n","    df = pd.read_csv(file_path)\n","\n","    print(\"Veri yükleme tamamlandı.\")\n","    print(\"İlk birkaç satır:\")\n","    print(df.head())\n","\n","    # Sütun adlarını yazdırma\n","    print(df.columns)\n","\n","    # Gerekli sütunları seçme ve eksik verileri temizleme\n","    # Doğru sütun adlarını kullanın\n","    df = df[['Country', 'Ingredients']].dropna()\n","\n","    print(\"Veri temizleme tamamlandı.\")\n","\n","    # Veri ön işleme\n","    df['Ingredients'] = df['Ingredients'].apply(preprocess_text)\n","    df['Ingredients'] = df['Ingredients'].apply(lemmatize_text)\n","\n","    print(\"Veri ön işleme tamamlandı.\")\n","\n","    # TF-IDF vektörizer ve Logistic Regression modeli pipeline oluşturma\n","    vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2))\n","    X = vectorizer.fit_transform(df['Ingredients'])\n","    y = df['Country']\n","\n","    print(\"Veri seti eğitim ve test setlerine ayrılıyor...\")\n","    # Veri setini eğitim ve test setlerine ayırma\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    print(\"Model eğitiliyor...\")\n","    # Modeli eğitme\n","    model = LogisticRegression(max_iter=1000, C=1.0)\n","    model.fit(X_train, y_train)\n","\n","    print(\"Model eğitildi. Test seti ile doğruluk ölçülüyor...\")\n","    # Test seti ile modelin doğruluğunu ölçme\n","    y_pred = model.predict(X_test)\n","    print(f'Test set accuracy: {accuracy_score(y_test, y_pred)}')\n","\n","    print(\"Model ve vektörizer kaydediliyor...\")\n","    # Modeli ve vektörizeri kaydetme\n","    joblib.dump(model, model_filename)\n","    joblib.dump(vectorizer, vectorizer_filename)\n","    print(\"Model ve vektörizer başarıyla kaydedildi.\")\n","\n","def load_model():\n","    if os.path.exists(model_filename) and os.path.exists(vectorizer_filename):\n","        print(\"Model ve vektörizer yükleniyor...\")\n","        model = joblib.load(model_filename)\n","        vectorizer = joblib.load(vectorizer_filename)\n","        print(\"Model ve vektörizer başarıyla yüklendi.\")\n","        return model, vectorizer\n","    else:\n","        print(\"Kaydedilmiş model bulunamadı. Model eğitiliyor...\")\n","        train_and_save_model()\n","        return load_model()\n","\n","def predict_country(ingredients):\n","    model, vectorizer = load_model()\n","    ingredients = preprocess_text(ingredients)\n","    ingredients = lemmatize_text(ingredients)\n","    ingredients_vector = vectorizer.transform([ingredients])\n","    country_prediction = model.predict(ingredients_vector)\n","    return country_prediction[0]\n","\n","# Kullanıcıdan malzemeleri alma ve tahmin yapma\n","query = input(\"Enter at least 5 ingredient in comma-seperated form\")\n","liste = query.split((\",\"))\n","if len(liste)>=5:\n","    user_ingredients = \"tomato, garlic, onion, olive oil\"\n","    predicted_country = predict_country(user_ingredients)\n","    print(f'The predicted country for the given ingredients is: {predicted_country}')\n","else:\n","    print(\"Invalid input\")\n","\n"]}]}